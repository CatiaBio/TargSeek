# ğŸ“ PureMilk Folder Organization

This document provides a comprehensive overview of the PureMilk project structure, file organization, and data flow patterns.

---

## ğŸ—ï¸ Project Root Structure

```
PureMilk/
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ CLAUDE.md                    # Technical documentation for Claude Code
â”œâ”€â”€ ğŸ“„ FOLDER_ORGANIZATION.md       # This file - project structure guide
â”œâ”€â”€ ğŸ“„ Snakefile                    # Main Snakemake workflow definition
â”œâ”€â”€ ğŸ“„ env.yml                      # Conda environment specification
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore patterns
â”œâ”€â”€ ğŸ“Š full_pipeline_performance.json # Pipeline performance metrics
â”œâ”€â”€ ğŸ“ config/                      # Configuration files and parameters
â”œâ”€â”€ ğŸ“ scripts/                     # Python scripts for pipeline execution
â”œâ”€â”€ ğŸ“ data/                        # Raw and processed data (gitignored)
â”œâ”€â”€ ğŸ“ results/                     # Pipeline outputs (gitignored)
â”œâ”€â”€ ğŸ“ logs/                        # Execution logs (gitignored)
â”œâ”€â”€ ğŸ“ .snakemake/                  # Snakemake metadata (gitignored)
â””â”€â”€ ğŸ“ backup_before_clean/         # Backup files (gitignored)
```

---

## âš™ï¸ Configuration Directory (`config/`)

### **Main Configuration**
```
config/
â”œâ”€â”€ ğŸ“„ config.yaml                  # Central pipeline configuration
â””â”€â”€ ğŸ“ login/                       # API credentials (gitignored)
    â”œâ”€â”€ ğŸ“„ bacdive_info.txt          # BacDive API credentials
    â”œâ”€â”€ ğŸ“„ ncbi_info.txt             # NCBI email and API key
    â”œâ”€â”€ ğŸ“„ bacdive_info.example.txt  # Template for BacDive config
    â””â”€â”€ ğŸ“„ ncbi_info.example.txt     # Template for NCBI config
```

### **Input Data Configuration**
```
config/
â”œâ”€â”€ ğŸ“ microbiome/                  # Species lists for analysis
â”‚   â””â”€â”€ ğŸ“ cow_milk/
â”‚       â””â”€â”€ ğŸ“„ unique_species.txt    # Target species list (297 species)
â””â”€â”€ ğŸ“ quickgo/                     # GO term and parameter configurations
    â”œâ”€â”€ ğŸ“„ go_ids.tsv                # Gene Ontology terms of interest
    â”œâ”€â”€ ğŸ“„ taxon_ids.tsv             # Taxonomic restrictions
    â”œâ”€â”€ ğŸ“„ surface_accessible.txt    # Surface accessibility criteria
    â”œâ”€â”€ ğŸ“„ params_1.json             # Primary parameter set
    â””â”€â”€ ğŸ“„ params_2.json             # Alternative parameter set
```

**Key Configuration Parameters:**
- **Coverage Thresholds**: 50% for both gram-positive and gram-negative
- **Species Counts**: 113 gram-positive, 184 gram-negative
- **API Rate Limits**: Built-in delays and retry mechanisms
- **Batch Sizes**: 10 species per UniProt batch query

---

## ğŸ”§ Scripts Directory (`scripts/`)

### **Core Pipeline Scripts**
```
scripts/
â”œâ”€â”€ ğŸ“„ classify_gram.py                    # BacDive taxonomic classification
â”œâ”€â”€ ğŸ“„ supplement_gram_classification.py   # Genus-based classification inference
â”œâ”€â”€ ğŸ“„ fetch_quickgo_data.py              # QuickGO API integration
â”œâ”€â”€ ğŸ“„ filter_quickgo_data.py             # Gene symbol filtering
â”œâ”€â”€ ğŸ“„ gene_taxa_coverage_cached.py       # NCBI coverage assessment with caching
â”œâ”€â”€ ğŸ“„ filter_coverage_count.py           # Coverage threshold filtering
â”œâ”€â”€ ğŸ“„ create_proteins_to_study_from_coverage.py # Coverage-based protein selection
â”œâ”€â”€ ğŸ“„ fetch_uniprot_info.py              # UniProt data enrichment
â”œâ”€â”€ ğŸ“„ filter_surface_accessible_proteins.py # Surface accessibility filtering
â”œâ”€â”€ ğŸ“„ create_gene_species_lists_from_coverage.py # Gene-specific species lists
â””â”€â”€ ğŸ“„ download_proteins_combined.py      # Multi-stage protein downloading
```

### **3D Structure & MSA Scripts**
```
scripts/
â”œâ”€â”€ ğŸ“„ download_3d_structures.py          # PDB structure downloading
â”œâ”€â”€ ğŸ“„ get_msa_sequences.py               # MSA sequence selection with 3D priority
â”œâ”€â”€ ğŸ“„ run_mafft_alignments.py           # MAFFT alignment execution
â”œâ”€â”€ ğŸ“„ trim_alignments.py                # trimAl alignment optimization
â”œâ”€â”€ ğŸ“„ assess_alignment_quality_comparison.py # Quality assessment
â””â”€â”€ ğŸ“„ analyze_conservation_adaptive.py   # Conservation analysis
```

### **Advanced Analysis Scripts**
```
scripts/
â”œâ”€â”€ ğŸ“„ predict_epitopes.py               # IEDB epitope prediction integration
â”œâ”€â”€ ğŸ“„ generate_download_summary.py      # Download performance analysis
â”œâ”€â”€ ğŸ“„ generate_final_report.py          # HTML report generation
â””â”€â”€ ğŸ“„ monitor_pipeline.py               # Performance monitoring
```

### **Deprecated/Archive Scripts** (gitignored)
```
scripts/
â”œâ”€â”€ ğŸ“„ download_proteins_simple.py       # Simplified download (superseded)
â”œâ”€â”€ ğŸ“„ download_proteins_uniprot_iterative.py # UniProt-specific download
â”œâ”€â”€ ğŸ“„ download_proteins_ncbi_missing.py # NCBI fallback download
â””â”€â”€ ğŸ“„ analyze_conservation.py           # Basic conservation (superseded)
```

---

## ğŸ“Š Data Directory (`data/`) - Runtime Generated

### **BacDive Classification Data**
```
data/
â””â”€â”€ ğŸ“ bacdive/
    â””â”€â”€ ğŸ“ analysis_1/                   # Analysis-specific results
        â”œâ”€â”€ ğŸ“„ gram_raw.json             # Raw BacDive API responses
        â”œâ”€â”€ ğŸ“„ gram.tsv                  # Initial classification results
        â”œâ”€â”€ ğŸ“„ updated_gram.tsv          # Supplemented with genus inference
        â”œâ”€â”€ ğŸ“„ gram_positive.txt         # Gram-positive species list (113)
        â”œâ”€â”€ ğŸ“„ gram_negative.txt         # Gram-negative species list (184)
        â”œâ”€â”€ ğŸ“„ not_found.txt             # Species not found in BacDive
        â”œâ”€â”€ ğŸ“„ updated_not_found.txt     # Final unclassified species
        â”œâ”€â”€ ğŸ“„ errors.txt                # API errors encountered
        â””â”€â”€ ğŸ“„ downloaded.txt            # Successfully processed species
```

### **QuickGO Annotation Data**
```
data/
â””â”€â”€ ğŸ“ quickgo/
    â””â”€â”€ ğŸ“ params_1/                     # Parameter set specific data
        â”œâ”€â”€ ğŸ“„ annotations.tsv           # Raw GO annotations
        â”œâ”€â”€ ğŸ“„ gene_symbols.txt          # Extracted gene symbols
        â””â”€â”€ ğŸ“„ gene_symbols_filtered.txt # Filtered gene list (~186 genes)
```

---

## ğŸ“ˆ Results Directory (`results/`) - Pipeline Outputs

### **Coverage Analysis Results**
```
results/
â””â”€â”€ ğŸ“ coverage/
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_coverage.tsv      # Raw coverage data
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_coverage_count.tsv # Filtered (50% threshold)
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_negative_coverage.tsv
    â””â”€â”€ ğŸ“„ analysis_1_params_1_gram_negative_coverage_count.tsv
```

**Coverage File Structure:**
- `gene`: Gene symbol
- `species_with_gene`: Count of species containing the gene
- `coverage_percentage`: Percentage coverage across target species
- `species_names_with_gene`: Semicolon-separated species list

### **UniProt Enrichment Results**
```
results/
â””â”€â”€ ğŸ“ uniprot_info/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive_uniprot_info/
        â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_coverage_count_location.tsv # Main output
        â”œâ”€â”€ ğŸ“„ download_summary.txt                           # Processing summary
        â””â”€â”€ ğŸ“ cache/                                          # API response cache
            â”œâ”€â”€ ğŸ“„ uniprot_cache_bacteria_gene1.json
            â””â”€â”€ ğŸ“„ uniprot_cache_bacteria_gene2.json
```

### **Protein Selection Results**
```
results/
â””â”€â”€ ğŸ“ proteins_to_study/
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive.tsv              # Selected proteins (G+)
    â””â”€â”€ ğŸ“„ analysis_1_params_1_gram_negative.tsv              # Selected proteins (G-)
```

**Selected Proteins Structure:**
- `gene`: Gene symbol
- `go_cellular_component`: GO cellular component annotation
- `count`: Number of species with this gene
- `coverage_percentage`: Coverage percentage

### **Gene-Specific Species Lists**
```
results/
â””â”€â”€ ğŸ“ proteins_to_download/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ gene1.txt                 # Species list for gene1
        â”œâ”€â”€ ğŸ“„ gene2.txt                 # Species list for gene2
        â””â”€â”€ ğŸ“„ ...                       # One file per selected gene
```

### **Downloaded Protein Sequences**
```
results/
â””â”€â”€ ğŸ“ protein_fasta/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ .download_complete        # Sentinel file for successful completion
        â””â”€â”€ ğŸ“ gene1/                    # Gene-specific sequences
            â”œâ”€â”€ ğŸ“„ species1.fasta        # Protein sequences by species
            â”œâ”€â”€ ğŸ“„ species2.fasta
            â”œâ”€â”€ ğŸ“„ download_summary.json # Download statistics
            â””â”€â”€ ğŸ“„ not_found_species.txt # Failed downloads
```

### **3D Structure Integration**
```
results/
â””â”€â”€ ğŸ“ 3d_structures/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_summary.json # Structure overview
        â””â”€â”€ ğŸ“ gene1/                    # Gene-specific structures
            â”œâ”€â”€ ğŸ“„ 1ABC.pdb              # PDB structure files
            â”œâ”€â”€ ğŸ“„ 1ABC.fasta            # Corresponding sequences
            â”œâ”€â”€ ğŸ“„ structure_info.json   # Structure metadata
            â””â”€â”€ ğŸ“„ no_structures_found.txt # Marker for no structures
```

### **MSA Preparation**
```
results/
â””â”€â”€ ğŸ“ msa_sequences/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ gene1.fasta               # MSA-ready sequences (3D structure priority)
        â”œâ”€â”€ ğŸ“„ gene2.fasta
        â”œâ”€â”€ ğŸ“„ 3d_structure_selection_report.json # 3D structure tracking
        â””â”€â”€ ğŸ“„ 3d_structure_summary.txt  # Human-readable structure report
```

### **Multiple Sequence Alignments**
```
results/
â”œâ”€â”€ ğŸ“ msa_alignments/               # Raw MAFFT alignments
â”‚   â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
â”‚       â”œâ”€â”€ ğŸ“„ gene1_aligned.fasta
â”‚       â””â”€â”€ ğŸ“„ gene2_aligned.fasta
â”œâ”€â”€ ğŸ“ msa_trimmed/                  # trimAl optimized alignments
â”‚   â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
â”‚       â”œâ”€â”€ ğŸ“„ gene1_trimmed.fasta
â”‚       â””â”€â”€ ğŸ“„ gene2_trimmed.fasta
â””â”€â”€ ğŸ“ msa_quality/                  # Quality assessment
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ quality_comparison.tsv    # Raw vs trimmed comparison
        â”œâ”€â”€ ğŸ“„ quality_summary.json     # Aggregate statistics
        â””â”€â”€ ğŸ“„ gene1_quality_plot.png   # Quality visualization
```

### **Conservation Analysis**
```
results/
â””â”€â”€ ğŸ“ conservation/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ conservation_summary.tsv  # Per-gene conservation metrics
        â”œâ”€â”€ ğŸ“„ conservation_summary.json # Detailed statistics
        â””â”€â”€ ğŸ“ per_gene/                 # Gene-specific analysis
            â”œâ”€â”€ ğŸ“„ gene1_conservation.tsv # Position-specific scores
            â”œâ”€â”€ ğŸ“„ gene1_conservation.png # Conservation plot
            â””â”€â”€ ğŸ“ logos/                # Logo plots (if enabled)
                â””â”€â”€ ğŸ“„ gene1_logo_region1.png
```

### **Epitope Predictions**
```
results/
â””â”€â”€ ğŸ“ epitope_predictions/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ epitope_prediction_summary.json # Overall summary
        â”œâ”€â”€ ğŸ“„ epitope_prediction_summary.tsv  # Tabular summary
        â”œâ”€â”€ ğŸ“„ epitope_prediction_report.txt   # Human-readable report
        â””â”€â”€ ğŸ“ gene1/                          # Gene-specific predictions
            â”œâ”€â”€ ğŸ“„ gene1_epitopes.tsv          # Detailed predictions
            â””â”€â”€ ğŸ“„ gene1_epitope_summary.json  # Gene summary
```

**Epitope Prediction Structure:**
- **MHC Class I**: 9-10 amino acid peptides with HLA binding predictions
- **MHC Class II**: Variable length peptides with HLA-DR/DQ/DP predictions
- **B-cell**: Linear epitopes based on hydrophilicity and surface accessibility
- **Conservation Scoring**: Integration with position-specific conservation data

### **Download Performance Analysis**
```
results/
â””â”€â”€ ğŸ“ download_summary/
    â””â”€â”€ ğŸ“ analysis_1_params_1_gram_positive/
        â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_download_summary.tsv # Complete summary
        â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_selected_genes_download_summary.tsv # Selected only
        â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_download_stats.json # Statistics
        â””â”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_download_report.txt # Human-readable
```

### **Final Reports**
```
results/
â””â”€â”€ ğŸ“ reports/
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_final_report.html # Comprehensive HTML report
    â””â”€â”€ ğŸ“ assets/                               # Report assets (if any)
```

---

## ğŸ“ Logs Directory (`logs/`) - Execution Logs

```
logs/
â””â”€â”€ ğŸ“ coverage/                     # Coverage analysis logs
    â”œâ”€â”€ ğŸ“„ analysis_1_params_1_gram_positive_coverage.log
    â””â”€â”€ ğŸ“„ analysis_1_params_1_gram_negative_coverage.log
```

---

## ğŸ”„ Data Flow Patterns

### **File Naming Convention**
```
{analysis}_{paramset}_gram_{group}_{suffix}

Examples:
- analysis_1_params_1_gram_positive_coverage.tsv
- analysis_1_params_1_gram_negative_epitopes.json
```

### **Dependencies Chain**
```
Species List â†’ BacDive Classification â†’ QuickGO Genes â†’ Coverage Assessment 
    â†“
UniProt Enrichment â†’ Surface Filtering â†’ Gene Lists â†’ Protein Download
    â†“  
3D Structures â†’ MSA Sequences â†’ Alignments â†’ Quality Assessment
    â†“
Conservation Analysis â†’ Epitope Prediction â†’ Final Reports
```

### **Parallel Processing Points**
- **Coverage Assessment**: Gram-positive and negative processed in parallel
- **Protein Downloads**: Multiple genes downloaded simultaneously
- **MSA Generation**: Independent alignment jobs per gene
- **Quality Assessment**: Parallel evaluation of alignment methods

---

## ğŸ› ï¸ Maintenance & Cleanup

### **Cache Management**
- **UniProt Cache**: `results/uniprot_info/*/cache/` - Can be cleaned to force re-download
- **Snakemake Cache**: `.snakemake/` - Snakemake metadata, safe to remove
- **Backup Files**: `backup_before_clean/` - Manual backups, review before deletion

### **Space Optimization**
- **Large Files**: Raw alignment files in `msa_alignments/` can be compressed
- **Intermediate Data**: Coverage cache files can be removed after successful runs
- **Logs**: Old log files can be archived or removed

### **Resumable Components**
- **Downloads**: Sentinel files enable automatic resumption
- **Coverage Analysis**: Cached results prevent re-computation
- **3D Structures**: Existing PDB files are not re-downloaded

---

## ğŸ”’ Security & Credentials

### **Protected Files** (gitignored)
```
config/login/
â”œâ”€â”€ ğŸ“„ bacdive_info.txt     # BacDive username/password
â””â”€â”€ ğŸ“„ ncbi_info.txt        # NCBI email/API key
```

### **Template Files** (version controlled)
```
config/login/
â”œâ”€â”€ ğŸ“„ bacdive_info.example.txt
â””â”€â”€ ğŸ“„ ncbi_info.example.txt
```

**Note**: Never commit actual credentials to version control. Always use the example files as templates.

---

## ğŸ“Š Performance Considerations

### **Storage Requirements**
- **Minimal Run**: ~1-5 GB (selected genes only)
- **Full Analysis**: ~10-50 GB (complete dataset with structures)
- **Archive Storage**: ~100+ GB (with all intermediate files and plots)

### **Network Usage**
- **API Calls**: Thousands of requests to BacDive, QuickGO, UniProt, NCBI, PDB
- **Rate Limiting**: Built-in delays respect API limits
- **Caching**: Reduces redundant network requests

### **Computational Intensity**
- **CPU**: MSA generation and epitope prediction are CPU-intensive
- **Memory**: Large datasets may require 16+ GB RAM
- **I/O**: Frequent file operations during download and processing phases

---

## ğŸ¯ Git Tracking Policy

### âœ… **Tracked Files** (Essential for reproducibility)
```
ğŸ“„ Core Workflow
â”œâ”€â”€ Snakefile                    # Main pipeline definition
â”œâ”€â”€ env.yml                      # Environment specification
â”œâ”€â”€ config/config.yaml           # Central configuration
â””â”€â”€ config/login/*.example.txt   # Credential templates

ğŸ“„ Active Scripts
â”œâ”€â”€ scripts/classify_gram.py
â”œâ”€â”€ scripts/fetch_quickgo_data.py
â”œâ”€â”€ scripts/predict_epitopes.py
â””â”€â”€ [all core pipeline scripts]

ğŸ“„ Documentation
â”œâ”€â”€ README.md
â”œâ”€â”€ CLAUDE.md
â””â”€â”€ FOLDER_ORGANIZATION.md
```

### âŒ **Ignored Files** (Generated/sensitive content)
```
ğŸ“ Data & Results
â”œâ”€â”€ data/                        # All runtime data
â”œâ”€â”€ results/                     # All pipeline outputs
â”œâ”€â”€ logs/                        # Execution logs
â””â”€â”€ backup_before_clean/         # Backup files

ğŸ“ Credentials & Cache
â”œâ”€â”€ config/login/*.txt           # Actual API credentials
â”œâ”€â”€ .snakemake/                  # Snakemake metadata
â””â”€â”€ cache/                       # API response cache

ğŸ“ Deprecated & Archive
â”œâ”€â”€ scripts/download_proteins_*.py  # Superseded scripts
â”œâ”€â”€ scripts/analyze_conservation.py # Old versions
â””â”€â”€ "Snakefile copy"             # Manual backups
```

---

## ğŸ”§ Development Workflow

### **Adding New Features**
1. Develop new scripts in `scripts/`
2. Test thoroughly with small datasets
3. Update `Snakefile` with new rules
4. Update documentation and configuration
5. Commit with descriptive messages

### **Managing Deprecated Code**
1. Scripts are gitignored when superseded
2. Working versions remain in the repository
3. Major changes documented in commit messages
4. Archive folders for manual cleanup

### **Configuration Management**
1. All parameters centralized in `config/config.yaml`
2. API credentials use template system
3. Environment dependencies managed via `env.yml`
4. Multiple analysis configurations supported

---

**ğŸ“ This organization supports scalable, reproducible, and maintainable bioinformatics workflows with comprehensive tracking and quality control.**